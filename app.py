import streamlit as st
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from google.cloud import bigquery
from google.oauth2 import service_account
from st_ant_tree import st_ant_tree

# ----------------------------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2)",
    layout="wide"
)

# ----------------------------------------------------------------------
# ãƒ†ãƒ¼ãƒ–ãƒ«è¨­å®š(å„ã‚¿ãƒ–ç”¨)
# ----------------------------------------------------------------------
TABLE_CONFIGS = {
    "äºˆç®—": {
        "dataset": st.secrets["bigquery"]["rawdata_dataset"],
        "table": st.secrets["bigquery"]["budget_table"],
        "columns": {
            'file_id': 'ãƒ•ã‚¡ã‚¤ãƒ«ID',
            'title': 'è³‡æ–™å',
            'ministry': 'çœåº',
            'agency': 'æœ¬å±€/å¤–å±€',
            'fiscal_year_start': 'å¹´åº¦',
            'category': 'ã‚«ãƒ†ã‚´ãƒª',
            'sub_category': 'è³‡æ–™å½¢å¼',
            'file_page': 'ãƒšãƒ¼ã‚¸',
            'source_url': 'URL',
            'content_text': 'æœ¬æ–‡'
        }
    },
    "ä¼šè­°è³‡æ–™": {
        "dataset": st.secrets["bigquery"]["rawdata_dataset"],
        "table": st.secrets["bigquery"]["council_table"],
        "columns": {
            'file_id': 'ãƒ•ã‚¡ã‚¤ãƒ«ID',
            'title': 'è³‡æ–™å',
            'ministry': 'çœåº',
            'agency': 'æœ¬å±€/å¤–å±€',
            'council': 'ä¼šè­°ä½“å',
            'fiscal_year_start': 'å¹´åº¦',
            'category': 'ã‚«ãƒ†ã‚´ãƒª',
            'sub_category': 'è³‡æ–™å½¢å¼',
            'file_page': 'ãƒšãƒ¼ã‚¸',
            'source_url': 'URL',
            'content_text': 'æœ¬æ–‡'
        }
    }
}

# ----------------------------------------------------------------------
# BigQuery æ¥ç¶š
# ----------------------------------------------------------------------

@st.cache_resource
def get_bigquery_client():
    """
    Streamlitã®secretsã‹ã‚‰GCPã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã‚’å–å¾—ã—ã€
    BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
    """
    try:
        creds_json = st.secrets["gcp_service_account"] 
        project_id = st.secrets['bigquery']['project_id']
        
        creds = service_account.Credentials.from_service_account_info(creds_json)
        client = bigquery.Client(credentials=creds, project=project_id)
        client.list_projects(max_results=1)
        
        return client
    except Exception as e:
        st.error(f"BigQueryæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

# ----------------------------------------------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ----------------------------------------------------------------------

def generate_session_id(user_id):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    å½¢å¼: ãƒ­ã‚°ã‚¤ãƒ³ID_YYYYMMDDhhmmssss
    """
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
    return f"{user_id}_{timestamp}"

if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False
if 'user_id' not in st.session_state:
    st.session_state['user_id'] = ""
if 'session_id' not in st.session_state:
    st.session_state['session_id'] = ""
if 'selected_agencies' not in st.session_state:
    st.session_state['selected_agencies'] = []
if 'selected_councils' not in st.session_state:
    st.session_state['selected_councils'] = []
if 'selected_categories' not in st.session_state:
    st.session_state['selected_categories'] = []
if 'selected_sub_categories' not in st.session_state:
    st.session_state['selected_sub_categories'] = []
if 'selected_years' not in st.session_state:
    st.session_state['selected_years'] = []
if 'search_results' not in st.session_state:
    st.session_state['search_results'] = None

# ----------------------------------------------------------------------
# èªè¨¼
# ----------------------------------------------------------------------

def log_login_to_bigquery(_bq_client, input_user_id, input_password, login_result, session_id):
    """
    ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œãƒ­ã‚°ã‚’BigQueryã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    log_table_id = (
        f"{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['log_login_table']}"
    )
    
    try:
        rows_to_insert = [
            {
                "timestamp": pd.Timestamp.now(tz='Asia/Tokyo').isoformat(),
                "id": input_user_id,
                "password": input_password,
                "result": login_result,
                "sessionId": session_id
            }
        ]
        
        _bq_client.insert_rows_json(log_table_id, rows_to_insert)
    except Exception as e:
        st.warning(f"ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def check_credentials_bigquery(bq_client, user_id, password):
    """
    BigQueryã®èªè¨¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    """
    auth_table_id_str = (
        f"`{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['auth_table']}`"
    )
    
    try:
        query = f"""
            SELECT id 
            FROM {auth_table_id_str}
            WHERE id = @user_id 
            AND pw = @password
            AND is_alive = TRUE
            LIMIT 1
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("user_id", "STRING", user_id),
                bigquery.ScalarQueryParameter("password", "STRING", password),
            ]
        )
        
        query_job = bq_client.query(query, job_config=job_config)
        results = query_job.to_dataframe()
        
        return not results.empty
        
    except Exception as e:
        st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def show_login_form(bq_client):
    """
    ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    """
    st.title("çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2) - ãƒ­ã‚°ã‚¤ãƒ³")
    
    with st.form("login_form"):
        user_id = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")

        if submitted:
            if not user_id or not password:
                st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return

            with st.spinner("èªè¨¼ä¸­..."):
                session_id = generate_session_id(user_id)
                
                if check_credentials_bigquery(bq_client, user_id, password):
                    st.session_state['authenticated'] = True
                    st.session_state['user_id'] = user_id
                    st.session_state['session_id'] = session_id
                    log_login_to_bigquery(bq_client, user_id, password, 'success', session_id)
                    st.rerun()
                else:
                    log_login_to_bigquery(bq_client, user_id, password, 'failed', session_id)
                    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")

# ----------------------------------------------------------------------
# JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ----------------------------------------------------------------------

@st.cache_data
def load_ministry_tree():
    """
    choices/ministry_tree.jsonã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    file_path = Path(__file__).parent / "choices" / "ministry_tree.json"
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return []
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path}' ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
        return []

@st.cache_data(ttl=3600)
def load_council_list(_bq_client):
    """
    BigQueryã‹ã‚‰ä¼šè­°ä½“ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã€ãƒ„ãƒªãƒ¼å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚
    """
    try:
        query = f"""
            SELECT 
                title,
                value,
                ministry
            FROM `{st.secrets["bigquery"]["project_id"]}.{st.secrets["bigquery"]["rawdata_dataset"]}.{st.secrets["bigquery"]["council_list"]}`
            ORDER BY ministry, title
        """
        
        df = _bq_client.query(query).to_dataframe()
        
        if df.empty:
            st.warning("ä¼šè­°ä½“ãƒªã‚¹ãƒˆãŒç©ºã§ã™")
            return []
        
        # ministryã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãƒ„ãƒªãƒ¼å½¢å¼ã«å¤‰æ›
        tree_data = []
        ministry_groups = df.groupby('ministry')
        
        for ministry, group in ministry_groups:
            children = [
                {"title": row['title'], "value": row['value']}
                for _, row in group.iterrows()
            ]
            
            tree_data.append({
                "title": ministry,
                "value": f"{ministry}_parent",
                "children": children
            })
        
        return tree_data
    except Exception as e:
        st.error(f"ä¼šè­°ä½“ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        st.error(traceback.format_exc())
        return []

@st.cache_data
def load_filter_choices():
    """
    ã‚«ãƒ†ã‚´ãƒªã€è³‡æ–™å½¢å¼ã€å¹´åº¦ã®é¸æŠè‚¢ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    base_path = Path(__file__).parent / "choices"
    
    choices = {
        'category': [],
        'sub_category': [],
        'year': []
    }
    
    files = {
        'category': 'category.json',
        'sub_category': 'sub_category.json',
        'year': 'year.json'
    }
    
    for key, filename in files.items():
        file_path = base_path / filename
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                choices[key] = json.load(f)
        except FileNotFoundError:
            st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except json.JSONDecodeError:
            st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path}' ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
    
    return choices

@st.cache_data
def load_manual():
    """
    ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    manual_path = Path(__file__).parent / "docs" / "manual.md"
    try:
        with open(manual_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {manual_path}\n\ndocs/manual.md ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"

def extract_values_from_tree_result(tree_result):
    """
    st_ant_treeã®çµæœã‹ã‚‰é¸æŠã•ã‚ŒãŸå€¤ã®ãƒªã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    """
    if not tree_result:
        return []
    
    if isinstance(tree_result, list):
        return tree_result
    
    if isinstance(tree_result, dict):
        if 'checked' in tree_result:
            return tree_result['checked'] if isinstance(tree_result['checked'], list) else []
    
    return []

# ----------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ----------------------------------------------------------------------

def run_search(_bq_client, dataset, table, column_names, keyword, agencies, councils, categories, sub_categories, years):
    """
    æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    db_columns = list(column_names.keys())
    columns_str = ", ".join(db_columns)
    
    base_query = f"""
        SELECT 
            {columns_str}
        FROM `{st.secrets["bigquery"]["project_id"]}.{dataset}.{table}`
    """
    
    where_conditions = []
    query_params = []

    if agencies and len(agencies) > 0:
        where_conditions.append("agency IN UNNEST(@agencies)")
        query_params.append(bigquery.ArrayQueryParameter("agencies", "STRING", agencies))
    
    if councils and len(councils) > 0:
        where_conditions.append("council IN UNNEST(@councils)")
        query_params.append(bigquery.ArrayQueryParameter("councils", "STRING", councils))
        
    if categories:
        where_conditions.append("category IN UNNEST(@categories)")
        query_params.append(bigquery.ArrayQueryParameter("categories", "STRING", categories))

    if sub_categories:
        where_conditions.append("sub_category IN UNNEST(@sub_categories)")
        query_params.append(bigquery.ArrayQueryParameter("sub_categories", "STRING", sub_categories))

    if years:
        int_years = [int(y) for y in years]
        where_conditions.append("fiscal_year_start IN UNNEST(@years)")
        query_params.append(bigquery.ArrayQueryParameter("years", "INT64", int_years))

    if keyword:
        where_conditions.append("(LOWER(title) LIKE @keyword OR LOWER(content_text) LIKE @keyword)")
        query_params.append(bigquery.ScalarQueryParameter("keyword", "STRING", f"%{keyword.lower()}%"))

    if where_conditions:
        final_query = base_query + " WHERE " + " AND ".join(where_conditions)
    else:
        final_query = base_query
        
    final_query += " ORDER BY ministry, agency, category, fiscal_year_start"

    job_config = bigquery.QueryJobConfig(query_parameters=query_params)
    
    try:
        df = _bq_client.query(final_query, job_config=job_config).to_dataframe()
        df = df.rename(columns=column_names)
        return df
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def log_search_to_bigquery(_bq_client, keyword, agencies, councils, categories, sub_categories, years):
    """
    æ¤œç´¢ãƒ­ã‚°ã‚’BigQueryã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    log_table_id = (
        f"{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['log_search_table']}"
    )
    
    try:
        rows_to_insert = [
            {
                "timestamp": pd.Timestamp.now(tz='Asia/Tokyo').isoformat(),
                "sessionId": st.session_state['session_id'],
                "keyword": keyword if keyword else "",
                "filter_ministries": ", ".join(agencies) if agencies else "",
                "filter_councils": ", ".join(councils) if councils else "",
                "filter_category": ", ".join(categories) if categories else "",
                "filter_subcategory": ", ".join(sub_categories) if sub_categories else "",
                "filter_year": ", ".join([str(y) for y in years]) if years else ""
            }
        ]
        
        errors = _bq_client.insert_rows_json(log_table_id, rows_to_insert)
        if errors:
            st.warning(f"æ¤œç´¢ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {errors}")
    except Exception as e:
        st.warning(f"æ¤œç´¢ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def main_app(bq_client):
    """
    èªè¨¼å¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    """
    st.title("çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2)")
    
    filter_choices = load_filter_choices()
    
    st.sidebar.header("ğŸ”½ æ¡ä»¶çµã‚Šè¾¼ã¿")
    
    st.sidebar.markdown("---")
    
    keyword = st.sidebar.text_input(
        "**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**", 
        placeholder="ä¾‹:AI æ´»ç”¨",
        help="è¤‡æ•°ã®å ´åˆã¯ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦ãã ã•ã„")
    
    tree_data = load_ministry_tree()
    
    with st.sidebar:
        st.markdown("**çœåº**", help="å¤–å±€ãŒã‚ã‚‹å ´åˆã€ç®¡è½„çœåºã‚’é¸æŠã™ã‚‹ã¨å…¨ã¦é¸æŠã•ã‚Œã¾ã™")
        if tree_data:
            tree_result = st_ant_tree(
                treeData=tree_data,
                treeCheckable=True,
                allowClear=True,
                showSearch=True,
                key="agency_tree"
            )
            
            current_agencies = extract_values_from_tree_result(tree_result)
            st.session_state['selected_agencies'] = current_agencies
        else:
            st.error("çœåºãƒ„ãƒªãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    # ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ„ãƒªãƒ¼å½¢å¼ã«å¤‰æ›´
    with st.sidebar:
        st.markdown("**ã‚«ãƒ†ã‚´ãƒª**", help="è³‡æ–™ã®å¤§åˆ†é¡ã‚’é¸æŠã§ãã¾ã™")
        if filter_choices['category']:
            category_result = st_ant_tree(
                treeData=filter_choices['category'],
                treeCheckable=True,
                allowClear=True,
                showSearch=True,
                key="category_tree"
            )
            
            current_categories = extract_values_from_tree_result(category_result)
            st.session_state['selected_categories'] = current_categories
    
    # è³‡æ–™å½¢å¼ã‚’ãƒ„ãƒªãƒ¼å½¢å¼ã«å¤‰æ›´
    with st.sidebar:
        st.markdown("**è³‡æ–™å½¢å¼**", help="è³‡æ–™ã®è©³ç´°ãªå½¢å¼ã‚’é¸æŠã§ãã¾ã™")
        if filter_choices['sub_category']:
            sub_category_result = st_ant_tree(
                treeData=filter_choices['sub_category'],
                treeCheckable=True,
                allowClear=True,
                showSearch=True,
                key="sub_category_tree"
            )
            
            current_sub_categories = extract_values_from_tree_result(sub_category_result)
            st.session_state['selected_sub_categories'] = current_sub_categories

    
    # å¹´åº¦ã‚’ãƒ„ãƒªãƒ¼å½¢å¼ã«å¤‰æ›´(ãƒ•ãƒ©ãƒƒãƒˆãƒªã‚¹ãƒˆã¨ã—ã¦è¡¨ç¤º)
    with st.sidebar:
        st.markdown("**å¹´åº¦**", help="å¯¾è±¡å¹´åº¦ã‚’é¸æŠã§ãã¾ã™(è¤‡æ•°é¸æŠå¯)")
        if filter_choices['year']:
            year_result = st_ant_tree(
                treeData=filter_choices['year'],
                treeCheckable=True,
                allowClear=True,
                showSearch=True,
                key="year_tree"
            )
            
            current_years = extract_values_from_tree_result(year_result)
            st.session_state['selected_years'] = current_years
    
    council_tree_data = load_council_list(bq_client)
    
    with st.sidebar:
        st.markdown("**ä¼šè­°ä½“(ä¼šè­°è³‡æ–™ã®ã¿)**", help="ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã¨ä¼šè­°ä½“åè‡ªä½“ã‚’çµã‚Šè¾¼ã¿æ¤œç´¢ã§ãã¾ã™")
        if council_tree_data:
            council_result = st_ant_tree(
                treeData=council_tree_data,
                treeCheckable=True,
                allowClear=True,
                showSearch=True,
                key="council_tree"
            )
            
            current_councils = extract_values_from_tree_result(council_result)
            st.session_state['selected_councils'] = current_councils
        else:
            st.info("ä¼šè­°ä½“ãƒªã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
    
    st.sidebar.markdown("---")
    
    search_button = st.sidebar.button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)
    
    st.sidebar.markdown("")
    
    if st.sidebar.button("ãƒ•ã‚£ãƒ«ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state['selected_agencies'] = []
        st.session_state['selected_councils'] = []
        st.session_state['selected_categories'] = []
        st.session_state['selected_sub_categories'] = []
        st.session_state['selected_years'] = []
        st.session_state['search_results'] = None
        st.rerun()
    
    st.sidebar.markdown("")
    
    if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", use_container_width=True):
        st.session_state['authenticated'] = False
        st.session_state['user_id'] = ""
        st.session_state['session_id'] = ""
        st.session_state['selected_agencies'] = []
        st.session_state['selected_councils'] = []
        st.session_state['selected_categories'] = []
        st.session_state['selected_sub_categories'] = []
        st.session_state['selected_years'] = []
        st.session_state['search_results'] = None
        st.rerun()

    st.markdown("---")

    if search_button:
        agencies = st.session_state.get('selected_agencies', [])
        councils = st.session_state.get('selected_councils', [])
        categories = st.session_state.get('selected_categories', [])
        sub_categories = st.session_state.get('selected_sub_categories', [])
        years = st.session_state.get('selected_years', [])
        
        log_search_to_bigquery(
            bq_client, keyword, agencies, councils, categories, 
            sub_categories, years
        )
        
        with st.spinner("ğŸ”„ æ¤œç´¢ä¸­..."):
            all_results = {}
            for tab_name, tab_config in TABLE_CONFIGS.items():
                if councils and len(councils) > 0 and tab_name == "äºˆç®—":
                    all_results[tab_name] = {
                        "df": pd.DataFrame(),
                        "column_names": tab_config["columns"]
                    }
                    continue
                
                dataset = tab_config["dataset"]
                table = tab_config["table"]
                column_names = tab_config["columns"]
                
                councils_for_search = councils if tab_name == "ä¼šè­°è³‡æ–™" else []
                
                results_df = run_search(
                    bq_client, dataset, table, column_names,
                    keyword, agencies, councils_for_search, categories, sub_categories, years
                )
                all_results[tab_name] = {
                    "df": results_df,
                    "column_names": column_names
                }
            
            st.session_state['search_results'] = all_results
    
    # æ¤œç´¢æ¡ä»¶ã®è¡¨ç¤º
    if st.session_state['search_results'] is not None:
        search_conditions = ["ğŸ“‹ é©ç”¨ä¸­ã®æ¤œç´¢æ¡ä»¶"]
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if keyword:
            search_conditions.append(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {keyword}")
        
        # çœåº
        agencies = st.session_state.get('selected_agencies', [])
        if agencies:
            if len(agencies) <= 3:
                search_conditions.append(f"**çœåº**: {', '.join(agencies)}")
            else:
                search_conditions.append(f"**çœåº**: {', '.join(agencies[:3])}... (è¨ˆ{len(agencies)}ä»¶)")
        
        # ã‚«ãƒ†ã‚´ãƒª
        categories = st.session_state.get('selected_categories', [])
        if categories:
            search_conditions.append(f"**ã‚«ãƒ†ã‚´ãƒª**: {', '.join(categories)}")
        
        # è³‡æ–™å½¢å¼
        sub_categories = st.session_state.get('selected_sub_categories', [])
        if sub_categories:
            if len(sub_categories) <= 3:
                search_conditions.append(f"**è³‡æ–™å½¢å¼**: {', '.join(sub_categories)}")
            else:
                search_conditions.append(f"**è³‡æ–™å½¢å¼**: {', '.join(sub_categories[:3])}... (è¨ˆ{len(sub_categories)}ä»¶)")
        
        # å¹´åº¦
        years = st.session_state.get('selected_years', [])
        if years:
            year_strs = [str(y) for y in sorted(years, reverse=True)]
            if len(year_strs) <= 5:
                search_conditions.append(f"**å¹´åº¦**: {', '.join(year_strs)}")
            else:
                search_conditions.append(f"**å¹´åº¦**: {', '.join(year_strs[:5])}... (è¨ˆ{len(year_strs)}ä»¶)")
        
        # ä¼šè­°ä½“
        councils = st.session_state.get('selected_councils', [])
        if councils:
            if len(councils) <= 3:
                search_conditions.append(f"**ä¼šè­°ä½“**: {', '.join(councils)}")
            else:
                search_conditions.append(f"**ä¼šè­°ä½“**: {', '.join(councils[:3])}... (è¨ˆ{len(councils)}ä»¶)")
        
        if search_conditions:
            st.info(" | ".join(search_conditions))
        else:
            st.info("**æ¡ä»¶**: ã™ã¹ã¦ã®è³‡æ–™")
        
        st.markdown("---")
    
    tabs = st.tabs(["äºˆç®—", "ä¼šè­°è³‡æ–™", "ğŸ”°ä½¿ç”¨æ–¹æ³•ãƒ»åéŒ²ãƒ‡ãƒ¼ã‚¿æƒ…å ±"])
    
    councils = st.session_state.get('selected_councils', [])
    
    with tabs[0]:
        if st.session_state['search_results'] is not None:
            if councils and len(councils) > 0:
                st.info("ä¼šè­°ä½“ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€äºˆç®—ã®æ¤œç´¢ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚")
            else:
                results_df = st.session_state['search_results']["äºˆç®—"]["df"]
                column_names = st.session_state['search_results']["äºˆç®—"]["column_names"]
                
                if not results_df.empty:
                    page_count = len(results_df)
                    file_id_col_jp = column_names.get('file_id', 'ãƒ•ã‚¡ã‚¤ãƒ«ID')
                    file_count = results_df[file_id_col_jp].nunique()
                    
                    st.success(f"{file_count}ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»{page_count}ãƒšãƒ¼ã‚¸ ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸ")
                    
                    display_df = results_df.drop(columns=[file_id_col_jp])
                    
                    url_col_jp = column_names.get('source_url', 'URL')
                    if url_col_jp in display_df.columns:
                        st.dataframe(
                            display_df, 
                            height=2000, 
                            use_container_width=True,
                            column_config={
                                url_col_jp: st.column_config.LinkColumn(
                                    url_col_jp,
                                    display_text="ğŸ“„ãƒªãƒ³ã‚¯"
                                )
                            }
                        )
                    else:
                        st.dataframe(display_df, height=2000, use_container_width=True)
                else:
                    st.info("è©²å½“ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.info("ğŸ” å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¡ä»¶ã‚’çµã‚Šè¾¼ã‚“ã§æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    
    with tabs[1]:
        if st.session_state['search_results'] is not None:
            results_df = st.session_state['search_results']["ä¼šè­°è³‡æ–™"]["df"]
            column_names = st.session_state['search_results']["ä¼šè­°è³‡æ–™"]["column_names"]
            
            if not results_df.empty:
                page_count = len(results_df)
                file_id_col_jp = column_names.get('file_id', 'ãƒ•ã‚¡ã‚¤ãƒ«ID')
                file_count = results_df[file_id_col_jp].nunique()
                
                st.success(f"{file_count}ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»{page_count}ãƒšãƒ¼ã‚¸ ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸ")
                
                display_df = results_df.drop(columns=[file_id_col_jp])
                
                url_col_jp = column_names.get('source_url', 'URL')
                if url_col_jp in display_df.columns:
                    st.dataframe(
                        display_df, 
                        height=2000, 
                        use_container_width=True,
                        column_config={
                            url_col_jp: st.column_config.LinkColumn(
                                url_col_jp,
                                display_text="ğŸ“„ãƒªãƒ³ã‚¯"
                            )
                        }
                    )
                else:
                    st.dataframe(display_df, height=2000, use_container_width=True)
            else:
                st.info("è©²å½“ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.info("ğŸ” å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¡ä»¶ã‚’çµã‚Šè¾¼ã‚“ã§æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    
    with tabs[2]:
        manual_content = load_manual()
        st.markdown(manual_content)

# ----------------------------------------------------------------------
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
# ----------------------------------------------------------------------

bq_client = get_bigquery_client()

if not st.session_state['authenticated']:
    show_login_form(bq_client)
else:
    main_app(bq_client)