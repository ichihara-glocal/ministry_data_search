import streamlit as st
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from google.cloud import bigquery
from google.oauth2 import service_account
from st_ant_tree import st_ant_tree

# ----------------------------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2)",
    layout="wide"
)

# ----------------------------------------------------------------------
# ãƒ†ãƒ¼ãƒ–ãƒ«è¨­å®š(å„ã‚¿ãƒ–ç”¨)
# ----------------------------------------------------------------------
TABLE_CONFIGS = {
    "äºˆç®—": {
        "dataset": st.secrets["bigquery"]["rawdata_dataset"],
        "table": st.secrets["bigquery"]["budget_table"],
        "columns": {
            'file_id': 'ãƒ•ã‚¡ã‚¤ãƒ«ID',
            'title': 'ã‚¿ã‚¤ãƒˆãƒ«',
            'ministry': 'çœåº',
            'agency': 'æœ¬å±€/å¤–å±€',
            'fiscal_year_start': 'å¹´åº¦',
            'category': 'ã‚«ãƒ†ã‚´ãƒª',
            'sub_category': 'è³‡æ–™å½¢å¼',
            'file_page': 'ãƒšãƒ¼ã‚¸',
            'source_url': 'URL',
            'content_text': 'æœ¬æ–‡'
        }
    },
    "ä¼šè­°è³‡æ–™": {
        "dataset": st.secrets["bigquery"]["rawdata_dataset"],
        "table": st.secrets["bigquery"]["council_table"],
        "columns": {
            'file_id': 'ãƒ•ã‚¡ã‚¤ãƒ«ID',
            'title': 'ã‚¿ã‚¤ãƒˆãƒ«',
            'ministry': 'çœåº',
            'agency': 'æœ¬å±€/å¤–å±€',
            'council': 'ä¼šè­°ä½“å',
            'fiscal_year_start': 'å¹´åº¦',
            'category': 'ã‚«ãƒ†ã‚´ãƒª',
            'sub_category': 'è³‡æ–™å½¢å¼',
            'file_page': 'ãƒšãƒ¼ã‚¸',
            'source_url': 'URL',
            'content_text': 'æœ¬æ–‡'
        }
    }
}

# ----------------------------------------------------------------------
# BigQuery æ¥ç¶š
# ----------------------------------------------------------------------

@st.cache_resource
def get_bigquery_client():
    """
    Streamlitã®secretsã‹ã‚‰GCPã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã‚’å–å¾—ã—ã€
    BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
    """
    try:
        creds_json = st.secrets["gcp_service_account"] 
        project_id = st.secrets['bigquery']['project_id']
        
        creds = service_account.Credentials.from_service_account_info(creds_json)
        client = bigquery.Client(credentials=creds, project=project_id)
        client.list_projects(max_results=1)
        
        return client
    except Exception as e:
        st.error(f"BigQueryæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

# ----------------------------------------------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ----------------------------------------------------------------------

def generate_session_id(user_id):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    å½¢å¼: ãƒ­ã‚°ã‚¤ãƒ³ID_YYYYMMDDhhmmssss
    """
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
    return f"{user_id}_{timestamp}"

if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False
if 'user_id' not in st.session_state:
    st.session_state['user_id'] = ""
if 'session_id' not in st.session_state:
    st.session_state['session_id'] = ""
if 'selected_agencies' not in st.session_state:
    st.session_state['selected_agencies'] = []
if 'search_results' not in st.session_state:
    st.session_state['search_results'] = None

# ----------------------------------------------------------------------
# èªè¨¼
# ----------------------------------------------------------------------

def log_login_to_bigquery(_bq_client, input_user_id, input_password, login_result, session_id):
    """
    ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œãƒ­ã‚°ã‚’BigQueryã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    log_table_id = (
        f"{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['log_login_table']}"
    )
    
    try:
        rows_to_insert = [
            {
                "timestamp": pd.Timestamp.now(tz='Asia/Tokyo').isoformat(),
                "id": input_user_id,
                "password": input_password,
                "result": login_result,
                "sessionId": session_id
            }
        ]
        
        _bq_client.insert_rows_json(log_table_id, rows_to_insert)
    except Exception as e:
        st.warning(f"ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def check_credentials_bigquery(bq_client, user_id, password):
    """
    BigQueryã®èªè¨¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    """
    auth_table_id_str = (
        f"`{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['auth_table']}`"
    )
    
    try:
        query = f"""
            SELECT id 
            FROM {auth_table_id_str}
            WHERE id = @user_id AND pw = @password
            LIMIT 1
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("user_id", "STRING", user_id),
                bigquery.ScalarQueryParameter("password", "STRING", password),
            ]
        )
        
        query_job = bq_client.query(query, job_config=job_config)
        results = query_job.to_dataframe()
        
        return not results.empty
        
    except Exception as e:
        st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def show_login_form(bq_client):
    """
    ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    """
    st.title("çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2) - ãƒ­ã‚°ã‚¤ãƒ³")
    
    with st.form("login_form"):
        user_id = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")

        if submitted:
            if not user_id or not password:
                st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return

            with st.spinner("èªè¨¼ä¸­..."):
                session_id = generate_session_id(user_id)
                
                if check_credentials_bigquery(bq_client, user_id, password):
                    st.session_state['authenticated'] = True
                    st.session_state['user_id'] = user_id
                    st.session_state['session_id'] = session_id
                    log_login_to_bigquery(bq_client, user_id, password, 'success', session_id)
                    st.rerun()
                else:
                    log_login_to_bigquery(bq_client, user_id, password, 'failed', session_id)
                    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")

# ----------------------------------------------------------------------
# ãƒ„ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ----------------------------------------------------------------------

@st.cache_data
def load_ministry_tree():
    """
    ministry_tree.jsonã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    file_path = Path(__file__).parent / "ministry_tree.json"
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path.name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return []
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path.name}' ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
        return []

def extract_agencies_from_tree_result(tree_result):
    """
    st_ant_treeã®çµæœã‹ã‚‰é¸æŠã•ã‚ŒãŸæœ¬å±€/å¤–å±€åã®ãƒªã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    """
    if not tree_result:
        return []
    
    if isinstance(tree_result, list):
        return tree_result
    
    if isinstance(tree_result, dict):
        if 'checked' in tree_result:
            return tree_result['checked'] if isinstance(tree_result['checked'], list) else []
    
    return []

# ----------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ----------------------------------------------------------------------

@st.cache_data(ttl=3600)
def load_metadata(_bq_client, dataset, table):
    """
    ãƒ•ã‚£ãƒ«ã‚¿ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    query = f"""
      SELECT 
        ministry,
        agency,
        category,
        sub_category,
        fiscal_year_start
      FROM `{st.secrets["bigquery"]["project_id"]}.{dataset}.{table}`
      GROUP BY ministry, agency, category, sub_category, fiscal_year_start
      ORDER BY ministry, agency, category, sub_category, fiscal_year_start
    """
    try:
        df = _bq_client.query(query).to_dataframe()
        return df
    except Exception as e:
        st.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def run_search(_bq_client, dataset, table, column_names, keyword, agencies, categories, sub_categories, years):
    """
    æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    db_columns = list(column_names.keys())
    columns_str = ", ".join(db_columns)
    
    base_query = f"""
        SELECT 
            {columns_str}
        FROM `{st.secrets["bigquery"]["project_id"]}.{dataset}.{table}`
    """
    
    where_conditions = []
    query_params = []

    if agencies and len(agencies) > 0:
        where_conditions.append("agency IN UNNEST(@agencies)")
        query_params.append(bigquery.ArrayQueryParameter("agencies", "STRING", agencies))
        
    if categories:
        where_conditions.append("category IN UNNEST(@categories)")
        query_params.append(bigquery.ArrayQueryParameter("categories", "STRING", categories))

    if sub_categories:
        where_conditions.append("sub_category IN UNNEST(@sub_categories)")
        query_params.append(bigquery.ArrayQueryParameter("sub_categories", "STRING", sub_categories))

    if years:
        int_years = [int(y) for y in years]
        where_conditions.append("fiscal_year_start IN UNNEST(@years)")
        query_params.append(bigquery.ArrayQueryParameter("years", "INT64", int_years))

    if keyword:
        where_conditions.append("(LOWER(title) LIKE @keyword OR LOWER(content_text) LIKE @keyword)")
        query_params.append(bigquery.ScalarQueryParameter("keyword", "STRING", f"%{keyword.lower()}%"))

    if where_conditions:
        final_query = base_query + " WHERE " + " AND ".join(where_conditions)
    else:
        final_query = base_query
        
    final_query += " ORDER BY ministry, agency, category, fiscal_year_start"

    job_config = bigquery.QueryJobConfig(query_parameters=query_params)
    
    try:
        df = _bq_client.query(final_query, job_config=job_config).to_dataframe()
        df = df.rename(columns=column_names)
        return df
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def log_search_to_bigquery(_bq_client, keyword, agencies, categories, sub_categories, years):
    """
    æ¤œç´¢ãƒ­ã‚°ã‚’BigQueryã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    log_table_id = (
        f"{st.secrets['bigquery']['project_id']}"
        f".{st.secrets['bigquery']['config_dataset']}"
        f".{st.secrets['bigquery']['log_search_table']}"
    )
    
    try:
        rows_to_insert = [
            {
                "timestamp": pd.Timestamp.now(tz='Asia/Tokyo').isoformat(),
                "sessionId": st.session_state['session_id'],
                "keyword": keyword if keyword else "",
                "filter_ministries": ", ".join(agencies) if agencies else "",
                "filter_category": ", ".join(categories) if categories else "",
                "filter_subcategory": ", ".join(sub_categories) if sub_categories else "",
                "filter_year": ", ".join([str(y) for y in years]) if years else ""
            }
        ]
        
        errors = _bq_client.insert_rows_json(log_table_id, rows_to_insert)
        if errors:
            st.warning(f"æ¤œç´¢ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {errors}")
    except Exception as e:
        st.warning(f"æ¤œç´¢ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def main_app(bq_client):
    """
    èªè¨¼å¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    """
    st.title("çœåºè³‡æ–™æ¤œç´¢ãƒ„ãƒ¼ãƒ« (Î²ç‰ˆ_v2)")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ (ãƒ•ã‚£ãƒ«ã‚¿)
    st.sidebar.header("ğŸ”½ æ¡ä»¶çµã‚Šè¾¼ã¿")
    
    keyword = st.sidebar.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›")
    
    # ãƒ„ãƒªãƒ¼å½¢å¼ã®çœåºé¸æŠ
    tree_data = load_ministry_tree()
    
    with st.sidebar:
        st.markdown("çœåº")
        if tree_data:
            tree_result = st_ant_tree(
                treeData=tree_data,
                treeCheckable=True,
                allowClear=True,
                key="agency_tree"
            )
            
            current_agencies = extract_agencies_from_tree_result(tree_result)
            st.session_state['selected_agencies'] = current_agencies
            
            if st.session_state['selected_agencies']:
                st.caption(f"é¸æŠä¸­: {', '.join(st.session_state['selected_agencies'])}")
            else:
                st.caption("é¸æŠãªã—")
        else:
            st.error("çœåºãƒ„ãƒªãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦èª­ã¿è¾¼ã¿
    with st.spinner("ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        all_meta_dfs = []
        for tab_name, tab_config in TABLE_CONFIGS.items():
            meta_df = load_metadata(bq_client, tab_config["dataset"], tab_config["table"])
            if not meta_df.empty:
                all_meta_dfs.append(meta_df)
        
        if all_meta_dfs:
            combined_meta_df = pd.concat(all_meta_dfs, ignore_index=True).drop_duplicates()
        else:
            st.sidebar.error("ãƒ•ã‚£ãƒ«ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.stop()

    categories = st.sidebar.multiselect(
        "ã‚«ãƒ†ã‚´ãƒª:",
        sorted(combined_meta_df['category'].unique())
    )
    sub_categories = st.sidebar.multiselect(
        "è³‡æ–™å½¢å¼:",
        sorted(combined_meta_df['sub_category'].unique())
    )
    years = st.sidebar.multiselect(
        "å¹´åº¦:",
        sorted(combined_meta_df['fiscal_year_start'].unique(), reverse=True)
    )

    st.sidebar.markdown("---")
    
    search_button = st.sidebar.button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)
    
    st.sidebar.markdown("")
    
    if st.sidebar.button("ãƒ•ã‚£ãƒ«ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state['selected_agencies'] = []
        st.session_state['search_results'] = None
        st.rerun()
    
    st.sidebar.markdown("")
    
    if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", use_container_width=True):
        st.session_state['authenticated'] = False
        st.session_state['user_id'] = ""
        st.session_state['session_id'] = ""
        st.session_state['selected_agencies'] = []
        st.session_state['search_results'] = None
        st.rerun()

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ (æ¤œç´¢çµæœã‚’ã‚¿ãƒ–ã§è¡¨ç¤º)
    st.markdown("---")

    if search_button:
        agencies = st.session_state.get('selected_agencies', [])
        
        # æ¤œç´¢ãƒ­ã‚°ã‚’è¨˜éŒ²ï¼ˆæ¤œç´¢å®Ÿè¡Œæ™‚ã«1å›ã ã‘ï¼‰
        log_search_to_bigquery(
            bq_client, keyword, agencies, categories, 
            sub_categories, years
        )
        
        with st.spinner("ğŸ”„ æ¤œç´¢ä¸­..."):
            all_results = {}
            for tab_name, tab_config in TABLE_CONFIGS.items():
                dataset = tab_config["dataset"]
                table = tab_config["table"]
                column_names = tab_config["columns"]
                
                results_df = run_search(
                    bq_client, dataset, table, column_names,
                    keyword, agencies, categories, sub_categories, years
                )
                all_results[tab_name] = {
                    "df": results_df,
                    "column_names": column_names
                }
            
            # æ¤œç´¢çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state['search_results'] = all_results
    
    # æ¤œç´¢çµæœã®è¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å–å¾—ï¼‰
    if st.session_state['search_results'] is not None:
        all_results = st.session_state['search_results']
        tabs = st.tabs(list(TABLE_CONFIGS.keys()))
        
        for i, (tab_name, tab) in enumerate(zip(TABLE_CONFIGS.keys(), tabs)):
            with tab:
                results_df = all_results[tab_name]["df"]
                column_names = all_results[tab_name]["column_names"]
                
                if not results_df.empty:
                    page_count = len(results_df)
                    file_id_col = column_names.get('file_id', 'file_id')
                    file_count = results_df[file_id_col].nunique()
                    
                    st.success(f"{file_count}ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»{page_count}ãƒšãƒ¼ã‚¸ ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸ")
                    
                    url_col = column_names.get('source_url')
                    if url_col:
                        st.dataframe(
                            results_df, 
                            height=2000, 
                            use_container_width=True,
                            column_config={
                                url_col: st.column_config.LinkColumn(
                                    url_col,
                                    display_text="ğŸ“„ãƒªãƒ³ã‚¯"
                                )
                            }
                        )
                    else:
                        st.dataframe(results_df, height=2000, use_container_width=True)
                else:
                    st.info("è©²å½“ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ----------------------------------------------------------------------
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
# ----------------------------------------------------------------------

bq_client = get_bigquery_client()

if not st.session_state['authenticated']:
    show_login_form(bq_client)
else:
    main_app(bq_client)